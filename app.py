import streamlit as st
import google.generativeai as genai
from PIL import Image
import speech_recognition as sr
from gtts import gTTS
from streamlit_mic_recorder import mic_recorder
import tempfile
import os
import re
from pydub import AudioSegment
import io
import random
import time

# --- Configuration ---
# Secrets á€‘á€²á€€ Key á€…á€¬á€›á€„á€ºá€¸á€€á€­á€¯ á€šá€°á€•á€«á€™á€šá€º
# á€…á€™á€ºá€¸á€á€•á€ºá€›á€”á€ºá€¡á€á€½á€€á€º Key á€á€…á€ºá€á€¯á€á€Šá€ºá€¸ á€›á€¾á€­á€›á€„á€ºá€œá€Šá€ºá€¸ ["KEY"] á€•á€¯á€¶á€…á€¶á€”á€²á€· á€‘á€Šá€·á€ºá€œá€­á€¯á€·á€›á€•á€«á€á€šá€º
api_keys = []

if "api_keys" in st.secrets:
    api_keys = st.secrets["api_keys"]
elif "GOOGLE_API_KEY" in st.secrets:
    # á€¡á€€á€šá€ºá Key á€¡á€Ÿá€±á€¬á€„á€ºá€¸á€•á€¯á€¶á€…á€¶á€•á€² á€›á€¾á€­á€á€±á€¸á€›á€„á€º List á€¡á€–á€¼á€…á€º á€•á€¼á€±á€¬á€„á€ºá€¸á€™á€šá€º
    api_keys = [st.secrets["GOOGLE_API_KEY"]]
else:
    # Secrets á€™á€›á€¾á€­á€›á€„á€º Code á€‘á€²á€€á€Ÿá€¬ á€šá€°á€™á€šá€º (á€™á€œá€¯á€¶á€á€¼á€¯á€¶á€•á€«)
    api_keys = ["YOUR_FALLBACK_API_KEY_HERE"]

# --- Page Setup ---
st.set_page_config(page_title="Smart Agri Pro", page_icon="ğŸŒ¾", layout="wide")

# --- CSS for Responsive Design ---
st.markdown("""
    <style>
    .main-title {
        text-align: center; color: #2E8B57; font-size: 3em; font-weight: bold; margin-bottom: 10px;
    }
    @media (max-width: 600px) {
        .main-title { font-size: 1.8em !important; margin-top: 0px; }
        section[data-testid="stSidebar"] { width: 250px !important; }
    }
    </style>
    <h1 class="main-title">ğŸŒ¾ Smart Agri - á€…á€­á€¯á€€á€ºá€•á€»á€­á€¯á€¸á€›á€±á€¸ á€œá€€á€ºá€‘á€±á€¬á€€á€º</h1>
""", unsafe_allow_html=True)

# --- Session State ---
if "history" not in st.session_state:
    st.session_state.history = []

# --- Helper Functions ---
def clean_text_for_speech(text):
    clean = re.sub(r'[\*\#\-\_]', '', text)
    clean = " ".join(clean.split())
    return clean

def text_to_speech(text):
    try:
        clean_text = clean_text_for_speech(text)
        tts = gTTS(text=clean_text, lang='my')
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as fp:
            tts.save(fp.name)
            return fp.name
    except:
        return None

def transcribe_audio(audio_bytes):
    r = sr.Recognizer()
    try:
        audio_segment = AudioSegment.from_file(io.BytesIO(audio_bytes))
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as fp:
            audio_segment.export(fp.name, format="wav")
            temp_filename = fp.name
        with sr.AudioFile(temp_filename) as source:
            audio_data = r.record(source)
            text = r.recognize_google(audio_data, language="my-MM")
        if os.path.exists(temp_filename):
            os.remove(temp_filename)
        return text
    except:
        return None

# --- âš ï¸ The Magic Function (Auto Key Rotator) ---
def get_ai_response_smart_rotate(prompt, image=None):
    """
    Key á€á€…á€ºá€á€¯ Error á€á€€á€ºá€›á€„á€º á€”á€±á€¬á€€á€ºá€á€…á€ºá€á€¯á€€á€­á€¯ á€¡á€œá€­á€¯á€¡á€œá€»á€±á€¬á€€á€º á€•á€¼á€±á€¬á€„á€ºá€¸á€á€¯á€¶á€¸á€™á€Šá€·á€º Function
    """
    # Key á€á€½á€±á€€á€­á€¯ á€™á€½á€¾á€±á€œá€­á€¯á€€á€ºá€•á€« (á€’á€«á€™á€¾ á€¡á€™á€¼á€²á€á€™á€ºá€¸ á€•á€‘á€™á€¡á€€á€±á€¬á€„á€·á€ºá€•á€² á€á€”á€ºá€•á€­á€™á€”á€±á€™á€¾á€¬á€•á€«)
    shuffled_keys = api_keys.copy()
    random.shuffle(shuffled_keys)
    
    last_error = None
    
    # Key á€á€…á€ºá€á€¯á€á€»á€„á€ºá€¸á€…á€®á€€á€­á€¯ á€œá€­á€¯á€€á€ºá€…á€™á€ºá€¸á€•á€«á€™á€šá€º
    for key in shuffled_keys:
        try:
            # 1. Key á€¡á€á€…á€ºá€”á€²á€· á€á€»á€­á€á€ºá€™á€šá€º
            genai.configure(api_key=key)
            model = genai.GenerativeModel('gemini-2.0-flash') # 2.0 á€€á€­á€¯á€•á€² á€¦á€¸á€…á€¬á€¸á€•á€±á€¸á€á€¯á€¶á€¸á€™á€šá€º
            
            # 2. á€™á€±á€¸á€á€½á€”á€ºá€¸á€‘á€¯á€á€ºá€™á€šá€º
            chat = model.start_chat(history=[])
            if image:
                response = chat.send_message([prompt, image])
            else:
                response = chat.send_message(prompt)
            
            # 3. á€¡á€±á€¬á€„á€ºá€™á€¼á€„á€ºá€›á€„á€º á€á€»á€€á€ºá€á€»á€„á€ºá€¸ á€¡á€–á€¼á€±á€•á€¼á€”á€ºá€•á€­á€¯á€·á€™á€šá€º (Loop á€›á€•á€ºá€™á€šá€º)
            return response.text
            
        except Exception as e:
            error_msg = str(e)
            last_error = error_msg
            # Error 429 (Quota) á€á€­á€¯á€·á€™á€Ÿá€¯á€á€º 403 (Permission) á€–á€¼á€…á€ºá€›á€„á€º á€”á€±á€¬á€€á€º Key á€€á€­á€¯ á€€á€°á€¸á€™á€šá€º
            if "429" in error_msg or "Quota" in error_msg or "403" in error_msg:
                print(f"Key Failed ({key[:5]}...), Switching to next key...")
                continue # Loop á€€á€­á€¯ á€†á€€á€ºá€•á€á€ºá€™á€šá€º (á€”á€±á€¬á€€á€º Key á€á€•á€ºá€™á€šá€º)
            else:
                # Quota á€•á€¼á€¿á€”á€¬ á€™á€Ÿá€¯á€á€ºá€˜á€² á€á€á€¼á€¬á€¸ Error (á€¥á€•á€™á€¬ á€¡á€„á€ºá€á€¬á€”á€€á€ºá€•á€¼á€á€ºá€á€¬) á€†á€­á€¯á€›á€„á€ºá€á€±á€¬á€· á€›á€•á€ºá€œá€­á€¯á€€á€ºá€™á€šá€º
                return f"á€…á€”á€…á€ºá€á€»á€­á€¯á€·á€šá€½á€„á€ºá€¸á€á€»á€€á€º á€›á€¾á€­á€”á€±á€•á€«á€á€Šá€º: {e}"
    
    # Key á€¡á€¬á€¸á€œá€¯á€¶á€¸ á€…á€™á€ºá€¸á€•á€¼á€®á€¸á€œá€­á€¯á€·á€™á€¾ á€™á€›á€›á€„á€ºá€á€±á€¬á€· á€á€€á€šá€º á€€á€¯á€”á€ºá€á€½á€¬á€¸á€•á€«á€•á€¼á€®
    return "âš ï¸ á€á€á€œá€±á€¸ á€…á€±á€¬á€„á€·á€ºá€•á€±á€¸á€•á€«... á€…á€”á€…á€ºá€¡á€œá€¯á€•á€ºá€™á€»á€¬á€¸á€”á€±á€•á€«á€á€Šá€ºá‹ (á) á€™á€­á€”á€…á€ºá€á€”á€·á€º á€”á€¬á€¸á€•á€¼á€®á€¸á€™á€¾ á€•á€¼á€”á€ºá€™á€±á€¸á€•á€±á€¸á€•á€«á€á€„á€ºá€—á€»á€¬á‹"

# --- Sidebar ---
with st.sidebar:
    st.header("âš™ï¸ á€†á€€á€ºá€á€„á€ºá€™á€»á€¬á€¸")
    app_mode = st.radio("á€œá€¯á€•á€ºá€†á€±á€¬á€„á€ºá€á€»á€€á€º á€›á€½á€±á€¸á€á€»á€šá€ºá€•á€«:",
        ["ğŸ¡ á€¡á€­á€™á€ºá€á€¼á€¶á€á€®á€¸á€”á€¾á€¶ (Garden)", "ğŸŒ¾ á€…á€•á€«á€¸á€…á€­á€¯á€€á€ºá€á€„á€ºá€¸ (Paddy)", "ğŸ‚ á€›á€±á€¬á€‚á€«á€…á€…á€ºá€†á€±á€¸ (Doctor)"])
    
    st.divider()
    if st.button("ğŸ”„ á€¡á€á€…á€ºá€•á€¼á€”á€ºá€™á€±á€¸á€™á€šá€º (Clear)"):
        st.session_state.history = []
        st.rerun()
    
    enable_voice = st.checkbox("ğŸ”Š á€¡á€á€¶á€–á€¼á€„á€·á€º á€•á€¼á€”á€ºá€–á€á€ºá€•á€¼á€•á€«", value=True)

# --- Main Logic ---
current_image = None 
context_prompt = ""

# 1. Input Form
with st.expander("ğŸ“ á€¡á€á€»á€€á€ºá€¡á€œá€€á€ºá€”á€¾á€„á€·á€º á€“á€¬á€á€ºá€•á€¯á€¶ á€–á€¼á€Šá€·á€ºá€›á€”á€º (á€”á€¾á€­á€•á€ºá€•á€«)", expanded=True):
    col1, col2 = st.columns([1, 1])
    uploaded_file = st.file_uploader("ğŸ“¸ á€“á€¬á€á€ºá€•á€¯á€¶ (Camera/Gallery):", type=["jpg", "png", "jpeg"], key="main_uploader")
    if uploaded_file:
        current_image = Image.open(uploaded_file)
        st.image(current_image, caption="á€á€„á€ºá€‘á€¬á€¸á€á€±á€¬á€•á€¯á€¶", width=200)

    if app_mode == "ğŸ¡ á€¡á€­á€™á€ºá€á€¼á€¶á€á€®á€¸á€”á€¾á€¶ (Garden)":
        with col1: plant_name = st.text_input("á€¡á€•á€„á€ºá€¡á€™á€Šá€º (á€¥á€•á€™á€¬- á€›á€¯á€¶á€¸á€•á€á€®):")
        with col2: tank_size = st.number_input("á€›á€±á€€á€”á€º (á€‚á€«á€œá€¶):", value=50)
        field_desc = st.text_input("á€…á€­á€¯á€€á€ºá€á€„á€ºá€¸ á€¡á€”á€±á€¡á€‘á€¬á€¸ (á€”á€±á€›á€±á€¬á€„á€º/á€™á€¼á€±):")
        if plant_name: context_prompt = f"á€¡á€•á€„á€º: {plant_name}. á€›á€±á€€á€”á€º: {tank_size} á€‚á€«á€œá€¶. á€™á€¼á€±: {field_desc}. (á€…á€­á€¯á€€á€ºá€•á€»á€­á€¯á€¸á€”á€Šá€ºá€¸á€”á€¾á€„á€·á€º á€™á€¼á€±á€á€¼á€‡á€¬ á€¡á€€á€¼á€¶á€•á€±á€¸á€•á€«)"

    elif app_mode == "ğŸŒ¾ á€…á€•á€«á€¸á€…á€­á€¯á€€á€ºá€á€„á€ºá€¸ (Paddy)":
        days = st.slider("á€…á€•á€«á€¸á€á€€á€ºá€á€™á€ºá€¸ (á€›á€€á€º):", 1, 120, 30)
        acres = st.number_input("á€…á€­á€¯á€€á€ºá€§á€€:", value=5)
        status = st.text_input("á€œá€€á€ºá€›á€¾á€­ á€¡á€•á€„á€ºá€¡á€á€¼á€±á€¡á€”á€±:")
        context_prompt = f"á€…á€•á€«á€¸á€á€€á€ºá€á€™á€ºá€¸: {days} á€›á€€á€º. á€…á€­á€¯á€€á€ºá€§á€€: {acres} á€§á€€. á€¡á€á€¼á€±á€¡á€”á€±: {status}. (á€œá€­á€¯á€¡á€•á€ºá€á€±á€¬ á€›á€±áŠ á€™á€¼á€±á€á€¼á€‡á€¬á€”á€¾á€„á€·á€º á€†á€±á€¸ á€¡á€€á€¼á€¶á€•á€±á€¸á€•á€«)"

    elif app_mode == "ğŸ‚ á€›á€±á€¬á€‚á€«á€…á€…á€ºá€†á€±á€¸ (Doctor)":
        st.info("á€¡á€•á€„á€ºá€›á€±á€¬á€‚á€« á€•á€¯á€¶á€€á€­á€¯ á€¡á€•á€±á€«á€ºá€€ Upload á€á€œá€¯á€á€ºá€™á€¾á€¬ á€á€„á€ºá€•á€±á€¸á€•á€«á‹")
        context_prompt = "á€’á€®á€•á€¯á€¶á€‘á€²á€€ á€¡á€•á€„á€ºá€›á€±á€¬á€‚á€«á€€á€­á€¯ á€…á€…á€ºá€†á€±á€¸á€•á€¼á€®á€¸ á€€á€¯á€á€”á€Šá€ºá€¸ á€•á€¼á€±á€¬á€•á€¼á€•á€«á‹ (Burmese Language)"

# 2. Voice Input
st.write("ğŸ™ï¸ **á€¡á€á€¶á€–á€¼á€„á€·á€º á€™á€±á€¸á€›á€”á€º:**")
audio_blob = mic_recorder(start_prompt="ğŸ”´ á€”á€¾á€­á€•á€ºá á€•á€¼á€±á€¬á€•á€« (Start)", stop_prompt="â¬› á€›á€•á€ºá€™á€Šá€º (Stop)", key='recorder')

voice_text = ""
if audio_blob:
    with st.spinner("á€¡á€á€¶á€–á€á€ºá€”á€±á€á€Šá€º..."):
        voice_text = transcribe_audio(audio_blob['bytes'])

# 3. Chat Interface
chat_container = st.container()
with chat_container:
    for msg in st.session_state.history:
        with st.chat_message(msg["role"]):
            st.write(msg["content"])
            if "audio_path" in msg and msg["audio_path"]:
                st.audio(msg["audio_path"], format="audio/mp3")

# 4. Handle Inputs
user_query = None
if voice_text: user_query = voice_text
if prompt := st.chat_input("á€†á€€á€ºá€œá€€á€º á€™á€±á€¸á€™á€¼á€”á€ºá€¸á€œá€­á€¯á€á€Šá€ºá€™á€»á€¬á€¸ á€›á€±á€¸á€•á€«..."): user_query = prompt

# Chat Attachment
with st.expander("ğŸ“ á€“á€¬á€á€ºá€•á€¯á€¶ á€•á€°á€¸á€á€½á€²á€á€„á€ºá€›á€”á€º (Chat Attachment)", expanded=False):
    chat_upload = st.file_uploader("Chat á€¡á€á€½á€€á€º á€•á€¯á€¶á€›á€½á€±á€¸á€•á€«:", type=["jpg", "png", "jpeg"], key="chat_uploader")
    if chat_upload:
        current_image = Image.open(chat_upload)
        st.image(current_image, width=150, caption="á€•á€°á€¸á€á€½á€²á€™á€Šá€·á€ºá€•á€¯á€¶")

# Processing
if user_query:
    final_prompt = user_query
    if len(st.session_state.history) == 0 and context_prompt:
        final_prompt = f"{context_prompt} \n\n á€¡á€á€¯á€¶á€¸á€•á€¼á€¯á€á€°á€™á€±á€¸á€á€½á€”á€ºá€¸: {user_query}"

    st.session_state.history.append({"role": "user", "content": user_query})
    with st.chat_message("user"):
        st.write(user_query)
        if current_image and chat_upload: st.image(current_image, width=200)

    with st.chat_message("assistant"):
        with st.spinner("AI á€…á€‰á€ºá€¸á€…á€¬á€¸á€”á€±á€•á€«á€á€Šá€º (Smart Loading)..."):
            full_prompt = f"{final_prompt} (Please answer in Burmese language.)"
            if 'current_image' not in locals(): current_image = None
            
            # ğŸ”¥ á€’á€®á€”á€±á€›á€¬á€™á€¾á€¬ Function á€¡á€á€…á€ºá€€á€­á€¯ á€á€±á€«á€ºá€á€¯á€¶á€¸á€‘á€¬á€¸á€•á€«á€á€šá€º
            response_text = get_ai_response_smart_rotate(full_prompt, current_image)
            st.write(response_text)
            
            audio_file = None
            if enable_voice and "Error" not in response_text and "á€…á€±á€¬á€„á€·á€ºá€•á€±á€¸á€•á€«" not in response_text:
                audio_file = text_to_speech(response_text)
                if audio_file: st.audio(audio_file, format="audio/mp3")

            st.session_state.history.append({
                "role": "assistant", 
                "content": response_text,
                "audio_path": audio_file
            })
