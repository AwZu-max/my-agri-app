import streamlit as st
import google.generativeai as genai
from PIL import Image
import speech_recognition as sr
from gtts import gTTS
from streamlit_mic_recorder import mic_recorder
import tempfile
import os
import re
from pydub import AudioSegment
import io
import random
import time

# --- Page Config ---
st.set_page_config(page_title="Smart Agri Pro", page_icon="ğŸŒ¾", layout="wide")

# --- CSS for Mobile Polish (á€–á€¯á€”á€ºá€¸á€¡á€á€½á€€á€º á€’á€®á€‡á€­á€¯á€„á€ºá€¸á€•á€¼á€„á€ºá€†á€„á€ºá€á€»á€€á€º) ---
st.markdown("""
    <style>
    /* Desktop Title */
    .main-title {
        text-align: center; color: #2E8B57; font-size: 2.5em; font-weight: bold; margin-bottom: 20px;
    }
    
    /* Sub-header Styling */
    h2, h3 {
        color: #444 !important;
    }

    /* Mobile Responsive Fixes */
    @media (max-width: 600px) {
        /* á€á€±á€«á€„á€ºá€¸á€…á€‰á€ºá€€á€¼á€®á€¸á€€á€­á€¯ á€–á€¯á€”á€ºá€¸á€™á€¾á€¬ á€á€±á€¸á€™á€šá€º */
        .main-title { 
            font-size: 1.6em !important; 
            margin-bottom: 10px;
        }
        /* á€¡á€•á€­á€¯á€„á€ºá€¸á€á€±á€«á€„á€ºá€¸á€…á€‰á€ºá€á€½á€±á€€á€­á€¯á€œá€Šá€ºá€¸ á€á€±á€¸á€™á€šá€º */
        h2 {
            font-size: 1.3em !important;
        }
        h3 {
            font-size: 1.1em !important;
        }
        /* Sidebar á€€á€­á€¯ á€–á€¯á€”á€ºá€¸á€™á€¾á€¬ á€¡á€•á€¼á€Šá€·á€ºá€™á€•á€±á€«á€ºá€¡á€±á€¬á€„á€º */
        section[data-testid="stSidebar"] {
            width: 250px !important;
        }
        /* Chat Message á€á€½á€±á€€á€­á€¯ á€–á€¯á€”á€ºá€¸á€™á€¾á€¬ á€”á€±á€›á€¬á€á€»á€±á€¬á€„á€ºá€¡á€±á€¬á€„á€ºá€œá€¯á€•á€ºá€™á€šá€º */
        .stChatMessage {
            padding: 5px !important;
        }
    }
    </style>
""", unsafe_allow_html=True)

# --- Configuration & API Keys ---
api_keys = []
if "api_keys" in st.secrets:
    api_keys = st.secrets["api_keys"]
elif "GOOGLE_API_KEY" in st.secrets:
    api_keys = [st.secrets["GOOGLE_API_KEY"]]
else:
    api_keys = ["YOUR_API_KEY_HERE"]

# --- Session State ---
if "garden_history" not in st.session_state: st.session_state.garden_history = []
if "paddy_history" not in st.session_state: st.session_state.paddy_history = []
if "doctor_history" not in st.session_state: st.session_state.doctor_history = []

# --- Helper Functions ---
def clean_text_for_speech(text):
    clean = re.sub(r'[\*\#\-\_]', '', text)
    clean = " ".join(clean.split())
    return clean

def text_to_speech(text):
    try:
        clean_text = clean_text_for_speech(text)
        tts = gTTS(text=clean_text, lang='my')
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as fp:
            tts.save(fp.name)
            return fp.name
    except:
        return None

def transcribe_audio(audio_bytes):
    r = sr.Recognizer()
    try:
        audio_segment = AudioSegment.from_file(io.BytesIO(audio_bytes))
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as fp:
            audio_segment.export(fp.name, format="wav")
            temp_filename = fp.name
        with sr.AudioFile(temp_filename) as source:
            audio_data = r.record(source)
            text = r.recognize_google(audio_data, language="my-MM")
        if os.path.exists(temp_filename):
            os.remove(temp_filename)
        return text
    except:
        return None

def get_ai_response_smart(prompt, image=None):
    shuffled_keys = api_keys.copy()
    random.shuffle(shuffled_keys)
    
    for key in shuffled_keys:
        try:
            genai.configure(api_key=key)
            model = genai.GenerativeModel('gemini-2.0-flash')
            chat = model.start_chat(history=[])
            if image:
                response = chat.send_message([prompt, image])
            else:
                response = chat.send_message(prompt)
            
            final_text = response.text.replace("á€á€„á€ºá€—á€»á€¬", "á€›á€¾á€„á€º").replace("á€á€—á€»á€¬", "á€›á€¾á€„á€º").replace("à¸„à¸£à¸±à¸š", "á€›á€¾á€„á€º")
            return final_text
        except Exception as e:
            error_msg = str(e)
            if "429" in error_msg or "Quota" in error_msg or "403" in error_msg:
                continue
            return f"á€…á€”á€…á€ºá€á€»á€­á€¯á€·á€šá€½á€„á€ºá€¸á€á€»á€€á€º: {e}"
    return "âš ï¸ á€á€á€œá€±á€¸ á€…á€±á€¬á€„á€·á€ºá€•á€±á€¸á€•á€«á€›á€¾á€„á€º... (á) á€™á€­á€”á€…á€ºá€á€”á€·á€º á€”á€¬á€¸á€•á€¼á€®á€¸á€™á€¾ á€•á€¼á€”á€ºá€™á€±á€¸á€•á€±á€¸á€•á€«á€›á€¾á€„á€ºá‹"

# --- Main Layout ---
st.markdown('<h1 class="main-title">ğŸŒ¾ Smart Agri - á€…á€­á€¯á€€á€ºá€•á€»á€­á€¯á€¸á€›á€±á€¸ á€œá€€á€ºá€‘á€±á€¬á€€á€º</h1>', unsafe_allow_html=True)

# Sidebar
with st.sidebar:
    st.header("âš™ï¸ á€†á€€á€ºá€á€„á€º")
    app_mode = st.radio("á€œá€¯á€•á€ºá€†á€±á€¬á€„á€ºá€á€»á€€á€º á€›á€½á€±á€¸á€á€»á€šá€ºá€•á€«:",
        ["ğŸ¡ á€¡á€­á€™á€ºá€á€¼á€¶á€á€®á€¸á€”á€¾á€¶ (Garden)", "ğŸŒ¾ á€…á€•á€«á€¸á€…á€­á€¯á€€á€ºá€á€„á€ºá€¸ (Paddy)", "ğŸ‚ á€›á€±á€¬á€‚á€«á€…á€…á€ºá€†á€±á€¸ (Doctor)"])
    
    st.divider()
    enable_voice = st.checkbox("ğŸ”Š á€¡á€á€¶á€–á€¼á€„á€·á€º á€•á€¼á€”á€ºá€–á€á€ºá€•á€¼á€•á€«", value=True)
    
    if st.button("ğŸ—‘ï¸ á€™á€¾á€á€ºá€á€™á€ºá€¸á€–á€»á€€á€ºá€™á€Šá€º (Clear)"):
        if app_mode == "ğŸ¡ á€¡á€­á€™á€ºá€á€¼á€¶á€á€®á€¸á€”á€¾á€¶ (Garden)": st.session_state.garden_history = []
        elif app_mode == "ğŸŒ¾ á€…á€•á€«á€¸á€…á€­á€¯á€€á€ºá€á€„á€ºá€¸ (Paddy)": st.session_state.paddy_history = []
        elif app_mode == "ğŸ‚ á€›á€±á€¬á€‚á€«á€…á€…á€ºá€†á€±á€¸ (Doctor)": st.session_state.doctor_history = []
        st.rerun()

# Dashboard Layout
col_control, col_chat = st.columns([1, 2], gap="large")

# --- COLUMN 1: Inputs (Expander Added for Mobile) ---
with col_control:
    # ğŸ”¥ á€–á€¯á€”á€ºá€¸á€™á€¾á€¬ á€”á€±á€›á€¬á€™á€šá€°á€¡á€±á€¬á€„á€º Expander á€”á€²á€· á€¡á€¯á€•á€ºá€œá€­á€¯á€€á€ºá€•á€«á€•á€¼á€®
    with st.expander(f"ğŸ“ {app_mode} á€¡á€á€»á€€á€ºá€¡á€œá€€á€ºá€–á€¼á€Šá€·á€ºá€›á€”á€º (á€”á€¾á€­á€•á€ºá€•á€«)", expanded=True):
        
        context_prompt = ""
        current_image = None
        
        if app_mode == "ğŸ¡ á€¡á€­á€™á€ºá€á€¼á€¶á€á€®á€¸á€”á€¾á€¶ (Garden)":
            plant_name = st.text_input("á€¡á€•á€„á€ºá€¡á€™á€Šá€º:", placeholder="á€¥á€•á€™á€¬- á€›á€¯á€¶á€¸á€•á€á€®")
            tank_size = st.number_input("á€›á€±á€€á€”á€º (á€‚á€«á€œá€¶):", value=50)
            field_desc = st.text_input("á€™á€¼á€±á€¡á€”á€±á€¡á€‘á€¬á€¸:", placeholder="á€”á€±á€›á€±á€¬á€„á€ºá€›/á€™á€›")
            if plant_name:
                context_prompt = f"Context: á€¡á€•á€„á€º={plant_name}, á€›á€±á€€á€”á€º={tank_size}á€‚á€«á€œá€¶, á€™á€¼á€±={field_desc}."

        elif app_mode == "ğŸŒ¾ á€…á€•á€«á€¸á€…á€­á€¯á€€á€ºá€á€„á€ºá€¸ (Paddy)":
            days = st.slider("á€…á€•á€«á€¸á€á€€á€ºá€á€™á€ºá€¸ (á€›á€€á€º):", 1, 120, 30)
            acres = st.number_input("á€…á€­á€¯á€€á€ºá€§á€€:", value=5)
            status = st.text_input("á€¡á€•á€„á€º á€¡á€á€¼á€±á€¡á€”á€±:", placeholder="á€¡á€›á€½á€€á€ºá€á€«áŠ á€•á€­á€¯á€¸á€€á€»..")
            context_prompt = f"Context: á€…á€•á€«á€¸á€á€€á€ºá€á€™á€ºá€¸={days}á€›á€€á€º, á€…á€­á€¯á€€á€ºá€§á€€={acres}, á€¡á€á€¼á€±á€¡á€”á€±={status}."

        elif app_mode == "ğŸ‚ á€›á€±á€¬á€‚á€«á€…á€…á€ºá€†á€±á€¸ (Doctor)":
            st.info("á€“á€¬á€á€ºá€•á€¯á€¶á€á€„á€ºá€•á€±á€¸á€•á€«á€›á€¾á€„á€º ğŸ‘‡")
            uploaded_file = st.file_uploader("á€•á€¯á€¶á€›á€½á€±á€¸á€•á€«:", type=["jpg", "png", "jpeg"], key="doc_upload")
            if uploaded_file:
                current_image = Image.open(uploaded_file)
                st.image(current_image, caption="á€á€„á€ºá€‘á€¬á€¸á€á€±á€¬á€•á€¯á€¶", use_column_width=True)
                context_prompt = "Context: This is a plant disease image diagnosis request."

        # Common Upload & Voice
        if app_mode != "ğŸ‚ á€›á€±á€¬á€‚á€«á€…á€…á€ºá€†á€±á€¸ (Doctor)":
            st.write("---")
            uploaded_file = st.file_uploader("á€“á€¬á€á€ºá€•á€¯á€¶ (Optional):", type=["jpg", "png", "jpeg"], key="common_upload")
            if uploaded_file:
                current_image = Image.open(uploaded_file)
                st.image(current_image, caption="á€á€„á€ºá€‘á€¬á€¸á€á€±á€¬á€•á€¯á€¶", use_column_width=True)

        st.write("ğŸ™ï¸ **á€¡á€á€¶á€–á€¼á€„á€·á€º á€•á€¼á€±á€¬á€›á€”á€º:**")
        audio_blob = mic_recorder(start_prompt="ğŸ”´ Start", stop_prompt="â¬› Stop", key='recorder')

# --- COLUMN 2: Chat ---
with col_chat:
    if app_mode == "ğŸ¡ á€¡á€­á€™á€ºá€á€¼á€¶á€á€®á€¸á€”á€¾á€¶ (Garden)":
        current_history = st.session_state.garden_history
    elif app_mode == "ğŸŒ¾ á€…á€•á€«á€¸á€…á€­á€¯á€€á€ºá€á€„á€ºá€¸ (Paddy)":
        current_history = st.session_state.paddy_history
    else:
        current_history = st.session_state.doctor_history

    if len(current_history) == 0:
        st.info(f"á€™á€„á€ºá€¹á€‚á€œá€¬á€•á€«á€›á€¾á€„á€º.. '{app_mode}' á€¡á€á€½á€€á€º á€¡á€€á€¼á€¶á€‰á€¬á€á€ºá€™á€»á€¬á€¸ á€…á€á€„á€ºá€™á€±á€¸á€™á€¼á€”á€ºá€¸á€”á€­á€¯á€„á€ºá€•á€«á€•á€¼á€®á‹")

    chat_container = st.container()
    with chat_container:
        for msg in current_history:
            with st.chat_message(msg["role"]):
                st.write(msg["content"])
                if "image" in msg and msg["image"]:
                    st.image(msg["image"], width=200)
                if "audio_path" in msg and msg["audio_path"]:
                    st.audio(msg["audio_path"], format="audio/mp3")

    # Inputs Handling
    voice_text = ""
    if audio_blob:
        with st.spinner("á€¡á€á€¶á€–á€á€ºá€”á€±á€•á€«á€á€šá€ºá€›á€¾á€„á€º..."):
            voice_text = transcribe_audio(audio_blob['bytes'])
    
    user_query = None
    if voice_text: user_query = voice_text
    
    # Input box fixed styling
    if prompt := st.chat_input("á€™á€±á€¸á€á€½á€”á€ºá€¸ á€›á€±á€¸á€•á€«..."):
        user_query = prompt

    if user_query:
        current_history.append({"role": "user", "content": user_query, "image": current_image})
        with st.chat_message("user"):
            st.write(user_query)
            if current_image: st.image(current_image, width=200)

        with st.chat_message("assistant"):
            with st.spinner("á€…á€‰á€ºá€¸á€…á€¬á€¸á€”á€±á€•á€«á€á€šá€ºá€›á€¾á€„á€º..."):
                system_instruction = (
                    "You are a friendly female agricultural expert. "
                    "Speak naturally using 'Shin' (á€›á€¾á€„á€º). Keep sentences short."
                )
                full_prompt = f"{system_instruction}\n\n{context_prompt}\n\nUser Question: {user_query} (Answer in Burmese)"
                
                response_text = get_ai_response_smart(full_prompt, current_image)
                st.write(response_text)
                
                audio_file = None
                if enable_voice and "Error" not in response_text:
                    audio_file = text_to_speech(response_text)
                    if audio_file: st.audio(audio_file, format="audio/mp3")

                current_history.append({
                    "role": "assistant", 
                    "content": response_text,
                    "audio_path": audio_file
                })
